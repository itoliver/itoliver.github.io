<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[centos7部署kubernetes-cluser]]></title>
    <url>%2F2018%2F04%2F11%2Fcentos7-kubernetes-cluser%2F</url>
    <content type="text"><![CDATA[前言Kubernetes是Google开源的容器集群管理系统，其提供应用部署、维护、 扩展机制等功能，利用Kubernetes能方便地管理跨机器运行容器化的应用，是Docker分布式系统的解决方案。k8s里所有的资源都可以用yaml或Json定义。K8s基本概念 MasterMaster节点负责整个集群的控制和管理，所有的控制命令都是发给它，上面运行着一组关键进程： kube-apiserver：提供了HTTP REST接口，是k8s所有资源增删改查等操作的唯一入口，也是集群控制的入口。kube-controller-manager：所有资源的自动化控制中心。当集群状态与期望不同时，kcm会努力让集群恢复期望状态，比如：当一个pod死掉，kcm会努力新建一个pod来恢复对应replicas set期望的状态。kube-scheduler：负责Pod的调度。实际上，Master只是一个名义上的概念，三个关键的服务不一定需要运行在一个节点上。 NodeNode是工作负载节点，运行着Master分配的负载（Pod），但一个Node宕机时，其上的负载会被自动转移到其他Node上。其上运行的关键组件是： kubelet：负责Pod的生命周期管理，同时与Master密切协作，实现集群管理的基本功能。kube-proxy：实现Service的通信与负载均衡机制的重要组件，老版本主要通过设置iptables规则实现，新版1.9基于kube-proxy-lvs 实现。Docker Engine：Docker引擎，负责Docker的生命周期管理。 一、安装前准备1.操作系统详情需要三台主机，都最小化安装 centos7.3,并update到最新 [root@master ~]# cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) 角色 主机名 IP Master master 192.168.1.14 node1 slave-1 192.168.1.15 node2 slave-2 192.168.1.16 2.在每台主机上关闭firewalld改用iptables输入以下命令，关闭firewalld systemctl stop firewalld.service #停止firewall systemctl disable firewalld.service #禁止firewall开机启动 yum install iptables-* -y systemctl start iptables.service systemctl enable iptables.service 3.安装ntp服务yuminstall -y ntp wget net-tools systemctl start ntpd systemctl enable ntpd 二、安装配置注：kubernetes，etcd等已经进去centos epel源，可以直接yum安装（需要安装epel-release） 1.安装Kubernetes Master使用以下命令安装kubernetes 和 etcd yum install -y kubernetes etcd 编辑/etc/etcd/etcd.conf 使etcd监听所有的ip地址，确保下列行没有注释，并修改为下面的值 cat /etc/etcd/etcd.conf # [member] ETCD_NAME=default ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot; ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot; ETCD_INITIAL_CLUSTER=&quot;default=http://192.168.1.14:2380&quot; #[cluster] ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.1.14:2379&quot; 编辑Kubernetes API server的配置文件 /etc/kubernetes/apiserver，确保下列行没有被注释，并为下列的值 cat /etc/kubernetes/apiserver ### # kubernetes system config # # The following values are used to configure the kube-apiserver # # The address on the local server to listen to. KUBE_API_ADDRESS=&quot;--address=0.0.0.0&quot; # The port on the local server to listen on. KUBE_API_PORT=&quot;--port=8080&quot; # Port minions listen on KUBELET_PORT=&quot;--kubelet_port=10250&quot; # Comma separated list of nodes in the etcd cluster KUBE_ETCD_SERVERS=&quot;--etcd_servers=http://192.168.1.14:2379&quot; # Address range to use for services KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot; # default admission control policies KUBE_ADMISSION_CONTROL=&quot;--admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&quot; # Add your own! KUBE_API_ARGS=&quot;&quot; 启动etcd, kube-apiserver, kube-controller-manager and kube-scheduler服务，并设置开机自启 cat /script/kubenetes_service.sh for SERVICES in etcd kube-apiserver kube-controller-manager kube-scheduler; do systemctl restart $SERVICES systemctl enable $SERVICES systemctl status $SERVICES done sh /script/kubenetes_service.sh 在etcd中定义flannel network的配置，这些配置会被flannel service下发到nodes: etcdctl mk /centos.com/network/config &#39;{&quot;Network&quot;:&quot;172.17.0.0/16&quot;}&#39; 添加iptables规则，允许相应的端口 iptables -I INPUT -p tcp --dport 2379 -j ACCEPT iptables -I INPUT -p tcp --dport 10250 -j ACCEPT iptables -I INPUT -p tcp --dport 8080 -j ACCEPT iptables-save 或者写入iptables配置文件 /etc/sysconfig/iptables 查看节点信息（我们还没有配置节点信息，所以这里应该为空） kubectl get nodes NAME LABELS STATUS 2.安装Kubernetes Nodes注：下面这些步骤应该在node1和node2上执行（也可以添加更多的node） 使用yum安装kubernetes 和 flannel yum install -y flannel kubernetes 为flannel service配置etcd服务器，编辑/etc/sysconfig/flanneld文件中的下列行以连接到master cat /etc/sysconfig/flanneld FLANNEL_ETCD=&quot;http://192.168.1.14:2379&quot; #改为etcd服务器的ip FLANNEL_ETCD_PREFIX=&quot;/centos.com/network&quot; 编辑/etc/kubernetes/config 中kubernetes的默认配置，确保KUBE_MASTER的值是连接到Kubernetes master API server： cat /etc/kubernetes/config KUBE_MASTER=&quot;--master=http://192.168.1.14:8080&quot; 编辑/etc/kubernetes/kubelet 如下行： node1: cat /etc/kubernetes/kubelet KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot; KUBELET_PORT=&quot;--port=10250&quot; KUBELET_HOSTNAME=&quot;--hostname_override=192.168.1.15&quot; KUBELET_API_SERVER=&quot;--api_servers=http://192.168.1.14:8080&quot; KUBELET_ARGS=&quot;&quot; node2: cat /etc/kubernetes/kubelet KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot; KUBELET_PORT=&quot;--port=10250&quot; KUBELET_HOSTNAME=&quot;--hostname_override=192.168.1.16&quot; KUBELET_API_SERVER=&quot;--api_servers=http://192.168.1.14:8080&quot; KUBELET_ARGS=&quot;&quot; 启动kube-proxy, kubelet, docker 和 flanneld services服务，并设置开机自启 cat /script/kubernetes_node_service.sh for SERVICES in kube-proxy kubelet docker flanneld; do systemctl restart $SERVICES systemctl enable $SERVICES systemctl status $SERVICES done 在每个node节点，你应当注意到你有两块新的网卡docker0 和 flannel0。你应该得到不同的ip地址范围在flannel0上，就像下面这样： node1: ip a | grep flannel | grep inet inet 172.17.11.0/16 scope global flannel0 node2: ip a | grep flannel | grep inet inet 172.17.60.0/16 scope global flannel0 添加iptables规则： iptables -I INPUT -p tcp --dport 2379 -j ACCEPT iptables -I INPUT -p tcp --dport 10250 -j ACCEPT iptables -I INPUT -p tcp --dport 8080 -j ACCEPT 现在登陆kubernetes master节点验证minions的节点状态： kubectl get nodes NAME STATUS AGE 192.168.1.15 Ready 2h 192.168.1.16 Ready 2h 至此，kubernetes集群已经配置并运行了，我们可以继续下面的步骤。 三、创建 Pods (Containers)为了创建一个pod，我们需要在kubernetes master上面定义一个yaml 或者 json配置文件。然后使用kubectl命令创建pod mkdir -p /k8s/pods cd /k8s/pods/ 查看nginx.yaml内容如下： apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 创建pod: kubectl create -f nginx.yaml 此时有如下报错：Error from server: error when creating “nginx.yaml”: Pod “nginx” is forbidden: no API token found for service account default/default, retry after the token is automatically created and added to the service account解决办法是编辑/etc/kubernetes/apiserver 去除 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccount，并重启kube-apiserver.service服务： cat /etc/kubernetes/apiserver KUBE_ADMISSION_CONTROL=&quot;--admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot; systemctl restart kube-apiserver.service 之后重新创建pod: kubectl create -f nginx.yaml pods/nginx 查看pod: kubectl get pod nginx NAME READY STATUS RESTARTS AGE nginx 0/1 Image: nginx is not ready on the node 0 34s 这里STATUS一直是这个，创建不成功，下面排错。通过查看pod的描述发现如下错误：kubectl describe pod nginxWed, 28 Oct 2015 10:25:30 +0800 Wed, 28 Oct 2015 10:25:30 +0800 1 {kubelet 192.168.1.16} implicitly required container POD pulled Successfully pulled Pod container image “gcr.io/google_containers/pause:0.8.0”Wed, 28 Oct 2015 10:25:30 +0800 Wed, 28 Oct 2015 10:25:30 +0800 1 {kubelet 192.168.1.16} implicitly required container POD failed Failed to create docker container with error: no such imageWed, 28 Oct 2015 10:25:30 +0800 Wed, 28 Oct 2015 10:25:30 +0800 1 {kubelet 192.168.1.16} failedSync Error syncing pod, skipping: no such imageWed, 28 Oct 2015 10:27:30 +0800 Wed, 28 Oct 2015 10:29:30 +0800 2 {kubelet 192.168.1.16} implicitly required container POD failed Failed to pull image “gcr.io/google_containers/pause:0.8.0”: image pull failed for gcr.io/google_containers/pause:0.8.0, this may be because there are no credentials on this request. details: (API error (500): invalid registry endpoint “http://gcr.io/v0/&quot;. HTTPS attempt: unable to ping registry endpoint https://gcr.io/v0/v2 ping attempt failed with error: Get https://gcr.io/v2/: dial tcp 173.194.72.82:443: i/o timeout 这里可能会遇到pod状态一直处于Penning的问题，此时可以通过kubectl describe pods/pod-name来查看pod信息，如果没有出错信息，那么Minion一直处于下载镜像中，下载好之后pod即会成功启动。 从网上找到 pause:0.8.0 的镜像，然后再每个node上导入镜像： 请在境外docker服务器执行 docker pull 命令下载镜像 gcr.io/google_containers/pause:latest gcr.io/google_containers/pause:1.0 gcr.io/google_containers/pause:0.8.0 再用导出镜像 docker save -o pause.tar gcr.io/google_containers/pause gzip pause.tar 最后把这个包放到 kubernetes 环境所有的 docker 服务器上 docker load -i pause.tar.gz 在执行以下命令即可成功创建pod kubectl create -f nginx.yaml pods/nginx 查看pod kubectl get pod nginx NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 2min 前往nodes节点上查看docker images docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.access.redhat.com/rhel7/pod-infrastructure latest 34d3450d733b 10 weeks ago 205 MB gcr.io/google_containers/pause 0.8.0 bf595365a558 2 years ago 241.7 kB]]></content>
      <categories>
        <category>Docker</category>
        <category>Linux自动化建设</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux自动化运维</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[合格linux运维人员必会的30道shell编程企业实战题及讲解]]></title>
    <url>%2F2018%2F04%2F11%2F%E5%90%88%E6%A0%BClinux%E8%BF%90%E7%BB%B4%E4%BA%BA%E5%91%98%E5%BF%85%E4%BC%9A%E7%9A%8430%E9%81%93shell%E7%BC%96%E7%A8%8B%E4%BC%81%E4%B8%9A%E5%AE%9E%E6%88%98%E9%A2%98%E5%8F%8A%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言本题来自老男孩老师的博客，自己完成解答涉及到的题基本上都是在企业实战能遇到的，如果可以自行找出答案，薪资可以翻倍的，哈哈，偏题了呀，下面进入正题…… 企业实战题1监控MySQL主从同步是否异常，如果异常，则发送短信或者邮件给管理员。提示：如果没主从同步环境,可以用下面文本放到文件里读取来模拟：阶段1：开发一个守护进程脚本每30秒实现检测一次。阶段2：如果同步出现如下错误号（1158,1159,1008,1007,1062），则跳过错误。阶段3：请使用数组技术实现上述脚本（获取主从判断及错误号部分） [root@oldboy~]# mysql -uroot -p&#39;oldboy&#39; -S /data/3307/mysql.sock -e &quot;show slavestatus\G;&quot; *************************** 1. row *************************** Slave_IO_State:Waiting for master to send event Master_Host:10.0.0.179 #当前的mysql master服务器主机 Master_User: rep Master_Port: 3306 Connect_Retry: 60 Master_Log_File:mysql-bin.000013 Read_Master_Log_Pos: 502547 Relay_Log_File:relay-bin.000013 Relay_Log_Pos:251 Relay_Master_Log_File:mysql-bin.000013 Slave_IO_Running:Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: mysql Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 502547 Relay_Log_Space:502986 Until_Condition:None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 #和主库比同步延迟的秒数，这个参数很重要 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: 解答链接：http://www.cnblogs.com/oliver-blogs/p/7715648.html 企业实战题2使用for循环在/oldboy目录下通过随机小写10个字母加固定字符串oldboy批量创建10个html文件，名称例如为： [root@oldboy oldboy]# sh /server/scripts/oldboy.sh [root@oldboy oldboy]# ls coaolvajcq_oldboy.html qnvuxvicni_oldboy.html vioesjmcbu_oldboy.html gmkhrancxh_oldboy.html tmdjormaxr_oldboy.html wzewnojiwe_oldboy.html jdxexendbe_oldboy.html ugaywanjlm_oldboy.html xzzruhdzda_oldboy.html qcawgsrtkp_oldboy.html vfrphtqjpc_oldboy.html 解答链接：http://www.cnblogs.com/oliver-blogs/p/7715691.html 企业实战题3请用至少两种方法实现！将以上文件名中的oldboy全部改成oldgirl(用for循环实现),并且html改成大写。 解答链接：http://www.cnblogs.com/oliver-blogs/p/7715719.html 企业实战题4批量创建10个系统帐号oldboy01-oldboy10并设置密码（密码为随机8位字符串）。 解答链接：http://www.cnblogs.com/oliver-blogs/p/7715759.html 企业实战题5写一个脚本，实现判断10.0.0.0/24网络里，当前在线用户的IP有哪些（方法有很多） 解答链接：http://www.cnblogs.com/oliver-blogs/p/7715865.html 企业实战题6请用至少两种方法实现！写一个脚本解决DOS攻击生产案例提示：根据web日志或者或者网络连接数，监控当某个IP并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频率每隔3分钟。防火墙命令为：iptables -I INPUT -s 10.0.1.10 -j DROP。 解答链接：http://www.cnblogs.com/oliver-blogs/p/7716383.html 企业实战题7开发mysql多实例启动脚本：已知mysql多实例启动命令为：mysqld_safe–defaults-file=/data/3306/my.cnf &amp;停止命令为：mysqladmin -u root -poldboy123 -S /data/3306/mysql.sockshutdown请完成mysql多实例启动启动脚本的编写要求：用函数，case语句、if语句等实现。 解答链接：http://www.cnblogs.com/oliver-blogs/p/7722589.html 企业实战题8如何实现对MySQL数据库进行分库备份，请用脚本实现 解答链接：http://www.cnblogs.com/oliver-blogs/p/7723324.html 企业实战题9如何实现对MySQL数据库进行分库加分表备份，请用脚本实现 解答链接：http://www.cnblogs.com/oliver-blogs/p/7723362.html 企业实战题10请用至少两种方法实现！bash for循环打印下面这句话中字母数不大于6的单词(昆仑万维面试题)。I am oldboy teacher welcome to oldboy training class. 解答链接：http://www.cnblogs.com/oliver-blogs/p/7723392.html 企业实战题11开发shell脚本分别实现以脚本传参以及read读入的方式比较2个整数大小。以屏幕输出的方式提醒用户比较结果。注意：一共是开发2个脚本。当用脚本传参以及read读入的方式需要对变量是否为数字、并且传参个数做判断。解答链接：http://www.cnblogs.com/oliver-blogs/p/7723559.html 企业实战题12打印选择菜单，一键安装Web服务： [root@oldboyscripts]# sh menu.sh 1.[install lamp] 2.[install lnmp] 3.[exit] pls input the num you want: 要求： 1、当用户输入1时，输出“startinstalling lamp.”然后执行/server/scripts/lamp.sh，脚本内容输出”lampis installed”后退出脚本； 2、当用户输入2时，输出“startinstalling lnmp.”然后执行/server/scripts/lnmp.sh输出”lnmpis installed”后退出脚本; 3、当输入3时，退出当前菜单及脚本； 4、当输入任何其它字符，给出提示“Input error”后退出脚本。 5、要对执行的脚本进行相关条件判断，例如：脚本是否存在，是否可执行等。 解答链接：http://www.cnblogs.com/oliver-blogs/p/7723828.html 企业实战题131、监控web服务是否正常，不低于3种监控策略。 2、监控db服务是否正常，不低于3种监控策略。要求间隔1分钟，持续监控。 解答链接：http://www.cnblogs.com/oliver-blogs/p/7723849.html 企业实战题14监控memcache服务是否正常，模拟用户（web客户端）检测。 使用nc命令加上set/get来模拟检测，以及监控响应时间及命中率。 企业实战题15面试及实战考试题：监控web站点目录（/var/html/www）下所有文件是否被恶意篡改（文件内容被改了），如果有就打印改动的文件名（发邮件），定时任务每3分钟执行一次(10分钟时间完成)。 企业实战题16企业案例:写网络服务独立进程模式下rsync的系统启动脚本 例如：/etc/init.d/rsyncd{start|stop|restart} 。要求：1.要使用系统函数库技巧。2.要用函数，不能一坨SHI的方式。3.可被chkconfig管理。 企业实战题17老男孩教育天津项目学生实践抓阄题目： 好消息，老男孩培训学生外出企业项目实践机会（第6次）来了（本月中旬），但是，名额有限，队员限3人（班长带队）。 因此需要挑选学生，因此需要一个抓阄的程序： 要求： 1、执行脚本后，想去的同学输入英文名字全拼，产生随机数01-99之间的数字，数字越大就去参加项目实践，前面已经抓到的数字，下次不能在出现相同数字。 2、第一个输入名字后，屏幕输出信息，并将名字和数字记录到文件里，程序不能退出继续等待别的学生输入。 企业实战题18老男孩linux实践题： 已知下面的字符串是通过RANDOM随机数变量md5sum|cut-c 1-8截取后的结果，请破解这些字符串对应的md5sum前的RANDOM对应数字？ 21029299 00205d1c a3da1677 1f6d12dd 890684b 企业实战题19批量检查多个网站地址是否正常 要求：shell数组方法实现，检测策略尽量模拟用户访问思路 http://www.etiantian.org http://www.taobao.com http://oldboy.blog.51cto.com http://10.0.0.7 企业实战题20(中企动力)：：用shell处理以下内容 1、按单词出现频率降序排序！ 2、按字母出现频率降序排序！ the squid project provides a number of resources toassist users design,implement and support squid installations. Please browsethe documentation and support sections for more infomation 企业实战题21输出正方形、等腰三角形、直角梯形，见如下内容 http://oldboy.blog.51cto.com/2561410/1718607 企业实战题22开发通过web界面展示监控Nginx代理节点状态，效果图如下。 lvs+keepalived集群部分Shell企业案例： 企业实战题23【LVS主节点】手工开发ipvsadm管理lvs的脚本ip_vs 实现：/etc/init.d/lvs {start|stop|restart} 企业实战题24【LVS主节点】模拟keepalived健康检查功能管理LVS节点， 当节点挂掉（检测2次，间隔2秒）从服务器池中剔除，好了（检测2次，间隔2秒）加进来 提示：利用ipvsadm命令实现添加和减少LVS节点。 企业实战题25LVS客户端节点】开发LVS客户端设置VIP以及抑制ARP的管理脚本 实现：/etc/init.d/lvsclient {start|stop|restart} 企业实战题26【LVS备节点】模拟keepalved vrrp功能，监听主节点，如果主节点不可访问则备节点启动并配置LVS实现接管主节点的资源提供服务（提醒：注意ARP缓存） 企业实战题27请用shell或Python编写一个正方形(oldboy_square.sh)，接收用户输入的数字。 例如： [root@oldboy ~]# sh oldboy_square1.sh Please Enter a number:5 ++++++++++ ++++++++++ ++++++++++ ++++++++++ ++++++++++ [root@oldboy ~]# sh oldboy_square2.sh Please Enter a number:9 ■■■■■■■■■ ■■■■■■■■■ ■■■■■■■■■ ■■■■■■■■■ ■■■■■■■■■ ■■■■■■■■■ ■■■■■■■■■ ■■■■■■■■■ ■■■■■■■■■ 企业实战题28请用shell或Python编写一个等腰三角形(oldboy2_triangle.sh)，接收用户输入的数字。 例如： [root@oldboy ~]# sh oldboy2_triangle.sh Please Enter a number:5 * *** ***** ******* ********* [root@oldboy ~]# sh oldboy2_triangle.sh Please Enter a number:8 * *** ***** ******* ********* *********** ************* *************** 企业实战题29请用shell或Python编写一个画直角梯形程序(oldboy4.sh)，接收用户输入的参数n，m 例如： [root@oldboy ~]# sh oldboy4.sh 4 6 **** ***** ****** 27,28,29三道题参考http://oldboy.blog.51cto.com/2561410/1718607 企业实战题30写一套简单的企业代码上线发布系统案例，利用SVN对代码及配置文件进行管理，在办公室服务器上从svn取出指定版本的代码和配置，发布到IDC机房分发机服务器上，在分发服务器或者负载均衡器上或者应用服务器本地实现代码平滑发布、上线、回滚脚本（具体设计请参考课堂讲解的企业代码发布方案）。 企业实战题31请设计一套Git+Saltstack实现代码的线上发布及管理方案。]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux自动化运维</tag>
        <tag>shell</tag>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-nginx-php部署]]></title>
    <url>%2F2018%2F04%2F09%2Fdocker-nginx-php%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[前言nginx是web服务器常用的架构,是一个高性能的HTTP和反向代理服务器,也是一个IMAP/POP3/SMTP服务器。服务器环境nignx:基于docker最新版nginxphp:7.1.5 1.拉取nginx和php-fpm镜像docker pull nginx docker pull php:7.1.5-fpm #自定义版本 docker pull bitnami/php-fpm 2.创建nginx数据目录mkdir -p /opt/nginx/{conf,conf.d,html,log} mkdir -p /opt/php/conf 3.创建nginx default.conf,此配置是支持go语言的反向代理cat /opt/nginx/conf.d/default.conf &lt;&lt; EOF map $http_upgrade $connection_upgrade { default upgrade; &#39;&#39; close; } upstream gameweb { ip_hash; server 192.168.1.14:3001 weight=2; server 192.168.1.14:3002; } server { listen 3003; server_name master.localhost.com; error_log /var/log/nginx/gameweb_error.log debug; access_log /var/log/nginx/gameweb_access.log; location / { proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Nginx-Proxy true; proxy_pass http://gameweb; add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Credentials true; add_header Access-Control-Allow-Headers Content-Type,Accept; add_header Access-Control-Allow-Methods GET; } } server { listen 80 default_server; server_name _; root /usr/share/nginx/html; location / { index index.html index.htm index.php; autoindex off; } location ~ \.php(.*)$ { root /usr/share/nginx/html/; fastcgi_pass php:9000; fastcgi_index index.php; fastcgi_split_path_info ^((?U).+\.php)(/?.+)$; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info; include fastcgi_params; } } EOF 4.配置php测试文件tee /opt/nginx/html/index.php &lt;&lt;EOF &lt;?php echo &quot;TEST PAGE&quot; ?&gt; EOF # 5.启动php容器 docker run -tid \-p 9000:9000 \–name php-fpm \–restart=always \–privileged=true \-v /opt/php/conf/:/bitnami/php/conf/ \-v /opt/nginx/html:/usr/share/nginx/html \bitnami/php-fpm # 6.启动nginx容器 docker run -tid \–name nginx \–restart=always \-p 80:80 \–privileged=true \-v /opt/nginx/conf.d:/etc/nginx/conf.d \-v /opt/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \-v /opt/nginx/html:/usr/share/nginx/html \-v /opt/nginx/log:/var/log/nginx \–link php-fpm:php \nginx`]]></content>
      <categories>
        <category>dockers</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux自动化运维</tag>
        <tag>nginx</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-mariadb集群-主从同步]]></title>
    <url>%2F2018%2F04%2F09%2Fdocker-mariadb%E9%9B%86%E7%BE%A4-%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[前言MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 修改mariadb docker系统时间tzselect cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime master部署1.创建mariadb数据配置文件mkdir -p /opt/docker-mariadb/{data,conf.d,script} 2.拉取mairadb10.1.10镜像docker pull mariadb:10.1.10 3.创建mariadb配置文件tee /opt/docker-mariadb/conf.d/my.cnf &lt;&lt;EOF [mysqld] datadir=/var/lib/mysql socket=/run/mysqld/mysqld.sock server-id = 1 log_bin=master-bin relay-log=relay-bin expire_logs_days = 30 binlog_format=row sync_binlog = 1 #sync_master_info = 1 default-storage-engine=INNODB innodb_file_per_table = ON #innodb_flush_logs_at_trx_commit #innodb_support_xa = on character-set-server=utf8mb4 slow_query_log = 1 long_query_time = 2 log_output = &#39;TABLE&#39; [mysql] default-character-set=utf8mb4 auto-rehash [mysqld_safe] log-error=/var/log/mysql.log pid-file=/run/mysqld/mysqld.pid EOF 4.创建运行脚本tee /opt/docker-mariadb/script/mariadb.sh&lt;&lt;EOF #!/bin/bash docker run -tid \ --restart=always \ --name mariadb-master \ -p 3307:3306 \ -v /opt/docker-mariadb/data:/var/lib/mysql \ -v /opt/docker-mariadb/conf.d:/etc/mysql/conf.d \ -e MYSQL_ROOT_PASSWORD=123456 \ mariadb:10.1.10 查看docker容器运行状态 docker ps -a 5.进入mariadb容器docker exec -it mariadb-master bash 6.配置mysql master用户授权mysql -uroot -p grant replication slave,replication client on *.* to &#39;repluser&#39;@&#39;shangserver004&#39; identified by &#39;replpassword&#39;; flush privileges; show master status; slave部署1.创建mariadb数据配置文件mkdir -p /opt/docker-mariadb/{data,conf.d,script} 2.拉取mairadb10.1.10镜像docker pull mariadb:10.1.10 3.创建mariadb配置文件tee /opt/docker-mariadb/conf.d/my.cnf &lt;&lt;EOF [mysqld] datadir=/var/lib/mysql socket=/run/mysqld/mysqld.sock server-id = 2 #log_bin=slave-bin #binlog_format=row relay-log=relay-bin expire_logs_days = 30 read-only = on sync_binlog = 1 default-storage-engine=INNODB #sync_relay_log = 1 #sync_relay_log_info = 1 innodb_file_per_table = ON character-set-server=utf8mb4 slow_query_log = 1 long_query_time = 2 log_output = &#39;TABLE&#39; [mysql] default-character-set=utf8mb4 auto-rehash [mysqld_safe] log-error=/var/log/mysql.log pid-file=/run/mysqld/mysqld.pid EOF 4.创建运行脚本tee /opt/docker-mariadb/script/mariadb.sh&lt;&lt;EOF #!/bin/bash docker run -tid \ --restart=always \ --name mariadb-slave \ -p 3307:3306 \ -v /opt/docker-mariadb/data:/var/lib/mysql \ -v /opt/docker-mariadb/conf.d:/etc/mysql/conf.d \ -e MYSQL_ROOT_PASSWORD=123456 \ mariadb:10.1.10 EOF 查看docker容器运行状态 docker ps -a 5.进入mariadb容器docker exec -it mariadb-slave bash 6.配置mysql slavemysql -uroot -p change master to master_host=&#39;192.168.1.14&#39;, master_port=3307, master_user=&#39;repluser&#39;, master_password=&#39;replpassword&#39;, master_log_file=&#39;master-bin.000001&#39;, master_log_pos=674, master_connect_retry=5, master_heartbeat_period=2; star slave; show status slave;]]></content>
      <categories>
        <category>dockers</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mariadb</tag>
        <tag>linux自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker_swarm集群]]></title>
    <url>%2F2018%2F04%2F08%2Fdocker-swarm%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[前言Swarm项目是Docker公司发布三剑客中的一员，用来提供容器集群服务，目的是更好的帮助用户管理多个Docker Engine，方便用户使用，像使用Docker Engine一样使用容器集群服务。这次分享内容从Swarm项目现状、Swarm社区现状和Swarm未来的一些规划三方面介绍Swarm，目的是能让大家对Swarm有个完整的认识，并且希望更多的人采用到Swarm项目中来。此文主要是swarm docker集群部署，仅供参考 环境：centos7.2192.168.1.14 master swarm-manager rethinkdb controller swarm-agent consul-s1 registrator consul-template(nginx)192.168.1.15 slave-1 registrator swarm-agent consul-s2192.168.1.16 slave-2 registrator swarm-agent consul-s3docker-engine 17.05.0-ce 一、搭建docker集群环境1、先检查是否安装旧版本dockerrpm -qa|grep docker 如果有就先卸载 yum remove docker* 2、添加docker.repo安装源，写入文件tee /etc/yum.repos.d/docker.repo&lt;&lt;EOF [dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/7/ enabled=1 gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg EOF 3、安装dockeryum install docker-engine 4、配置防火墙firewall-cmd --permanent --add-port={2375/tcp,3375/tcp,8500/tcp,8300/tcp,8301/tcp,8301/udp,8302/tcp,8302/udp,8400/tcp,8500/tcp,8600/tcp,8600/udp,8080/tcp,28015/tcp,29015/tcp} firewall-cmd --reload firewall-cmd --list-all iptables内容（使用的iptables）*nat :PREROUTING ACCEPT [0:0] :INPUT ACCEPT [0:0] :OUTPUT ACCEPT [0:0] :POSTROUTING ACCEPT [0:0] :DOCKER - [0:0] -A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER -A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER -A POSTROUTING -s 192.168.0.0/16 ! -o docker0 -j MASQUERADE COMMIT # *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] :DOCKER - [0:0] -A FORWARD -o docker0 -j DOCKER -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT -A FORWARD -i docker0 ! -o docker0 -j ACCEPT -A FORWARD -i docker0 -o docker0 -j ACCEPT -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 21 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 2375 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 3375 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 8300 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 8301 -j ACCEPT -A INPUT -p udp -m state --state NEW -m udp --dport 8301 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 8302 -j ACCEPT -A INPUT -p udp -m state --state NEW -m udp --dport 8302 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 8400 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 8500 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 8600 -j ACCEPT -A INPUT -p udp -m state --state NEW -m udp --dport 8600 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 28015 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 29015 -j ACCEPT #-A INPUT -j REJECT --reject-with icmp-host-prohibited #-A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT 5、增加tcp监听端口,并配置docker加速修改/lib/systemd/system/docker.servicedaocloud加速 sed -i &#39;s/ExecStart=.*/ExecStart=\/usr\/bin\/dockerd -H unix\:\/\/\/var\/run\/docker.sock -D -H tcp\:\/\/0.0.0.0\:2375 --registry-mirror=http\:\/\/a582cc4e.m.daocloud.io --live-restore/g&#39; /lib/systemd/system/docker.service 私库 sed -i &#39;s/ExecStart=.*/ExecStart=\/usr\/bin\/dockerd -H unix\:\/\/\/var\/run\/docker.sock -D -H tcp\:\/\/0.0.0.0\:2375 --registry-mirror=http\:\/\/a582cc4e.m.daocloud.io --insecure-registry 192.168.1.14\:5000 --live-restore/g&#39; /lib/systemd/system/docker.service 阿里云加速 sed -i &#39;s/ExecStart=.*/ExecStart=\/usr\/bin\/dockerd -H unix\:\/\/\/var\/run\/docker.sock -D -H tcp\:\/\/0.0.0.0\:2375 --registry-mirror=https\:\/\/0xl18ug0.mirror.aliyuncs.com --live-restore/g&#39; /lib/systemd/system/docker.service 6、重启dockersystemctl daemon-reload systemctl enable docker.service systemctl restart docker.service ps -ef |grep docker #能看到docker启动以及2375端口 #7、安装pip以及docker api yum -y install epel-release yum -y install python-pip pip install docker-py docker-compose 8、创建consul用户及组groupadd -g 1005 consul useradd -u 105 -g 1005 -s /bin/false consul 9、创建consul数据存储文件夹mkdir -p /opt/consul/{data,conf} chown -R consul: /opt/consul 10、设置主机hosts，有多少台主机，就需要设置多少hostsvim /etc/hosts 192.168.1.14 master.localhost.com 192.168.1.15 slave1.localhost.com 192.168.1.16 slave2.localhost.com 二、配置consul cluster1、拉取consul镜像docker pull progrium/consul #提示：目录没有官方出consul镜像，以上consul镜像是官方推荐的第三方docker image 2、启动consul server 192.168.1.14docker run -d \ -p 8300:8300 \ -p 8301:8301 \ -p 8301:8301/udp \ -p 8302:8302 \ -p 8302:8302/udp \ -p 8400:8400 \ -p 8500:8500 \ -p 8600:53 \ -p 8600:53/udp \ -v /opt/consul/data:/data \ -h $HOSTNAME \ --restart=always \ --name=consul-s1 \ progrium/consul \ -server -bootstrap-expect=1 \ -ui-dir=/ui \ -client 0.0.0.0 \ -advertise 192.168.1.14 3、启动consul server 192.168.1.15docker run -d \ -p 8300:8300 \ -p 8301:8301 \ -p 8301:8301/udp \ -p 8302:8302 \ -p 8302:8302/udp \ -p 8400:8400 \ -p 8500:8500 \ -p 8600:53 \ -p 8600:53/udp \ -v /opt/consul/data:/data \ -h consul-s2 \ --restart=always \ --name=consul-s2 \ progrium/consul \ -server \ -ui-dir=/ui \ -client 0.0.0.0 \ -advertise 192.168.1.15 -join 192.168.1.14 4、启动consul client 192.168.1.16docker run -d \ -p 8300:8300 \ -p 8301:8301 \ -p 8301:8301/udp \ -p 8302:8302 \ -p 8302:8302/udp \ -p 8400:8400 \ -p 8500:8500 \ -p 8600:53 \ -p 8600:53/udp \ -v /opt/consul/data:/data \ -h consul-c1 \ --restart=always \ --name=consul-c1 \ progrium/consul \ -advertise 192.168.1.16 -join 192.168.1.14 三、registrator状态获取依次启动 docker run -d \ --restart=always \ --name=registrator \ --net=host \ -v /var/run/docker.sock:/tmp/docker.sock \ gliderlabs/registrator \ -ip 192.168.1.14 \ consul://192.168.1.14:8500 docker run -d \ --restart=always \ --name=registrator \ --net=host \ -v /var/run/docker.sock:/tmp/docker.sock \ gliderlabs/registrator \ -ip 192.168.1.15 \ consul://192.168.1.15:8500 docker run -d \ --restart=always \ --name=registrator \ --net=host \ -v /var/run/docker.sock:/tmp/docker.sock \ gliderlabs/registrator \ -ip 192.168.1.16 \ consul://192.168.1.16:8500 四、安装shipyard、swarm1、192.168.1.14 docker run -tid \ -p 3375:3375 \ --restart=always \ --name shipyard-swarm-manager \ swarm:latest \ manage --host tcp://0.0.0.0:3375 consul://192.168.1.14:8500 docker run -tid \ --restart=always \ --name=shipyard-rethinkdb \ -p 28015:28015 \ -p 29015:29015 \ -v /opt/rethinkdb:/data \ index.tenxcloud.com/docker_library/rethinkdb docker run -tid \ --restart=always \ --name shipyard-controller \ --link shipyard-rethinkdb:rethinkdb \ --link shipyard-swarm-manager:swarm \ -p 8080:8080 \ dockerclub/shipyard:latest \ server \ -d tcp://swarm:3375 docker run -tid \ --restart=always \ --name shipyard-swarm-agent \ swarm:latest \ join --addr 192.168.1.14:2375 consul://192.168.1.14:8500 2、安装swarm-agent主机192.168.1.15操作 docker run -tid \ --restart=always \ --name shipyard-swarm-agent \ swarm:latest \ join --addr 192.168.1.15:2375 consul://192.168.1.14:8500 主机192.168.1.16操作 docker run -tid \ --restart=always \ --name shipyard-swarm-agent \ swarm:latest \ join --addr 192.168.1.16:2375 consul://192.168.1.14:8500 五、安装haproxy或者nginx（192.168.1.14）1、安装haproxyyum -y install git patch gcc gcc-c++ readline-devel zlib-devel libffi-devel \ openssl openssl-devel make autoconf automake libtool bison libxml2 \ libxml2-devel libxslt-devel libyaml-devel python python-docutils \ cmake imake expat-devel libaio libaio-devel bzr ncurses-devel wget \ libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel \ pcre-devel curl-devel libmcrypt libmcrypt-devel cd /tmp wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.0.tar.gz tar -xvf /tmp/haproxy-1.7.0.tar.gz make TARGET=linux31 PREFIX=/opt/haproxy make install PREFIX=/opt/haproxy 2、配置haproxy.confvim /opt/haproxy/conf/haproxy.conf global log 127.0.0.1 local0 #log 127.0.0.1 local1 notice #log loghost local0 info maxconn 50000 chroot /opt/haproxy uid 99 gid 99 daemon nbproc 2 pidfile /opt/haproxy/run/haproxy.pid #debug #quiet defaults mode tcp option dontlognull option forwardfor option redispatch retries 2 balance static-rr stats enable stats uri /ha?stats #haproxy运行状态查看 自定义uri timeout connect 3000 timeout client 50000 timeout server 50000 listen admin_stat # 监听端口 bind *:8888 # http的7层模式 mode http #log global # 统计页面自动刷新时间 stats refresh 30s # 统计页面URL stats uri /admin?stats # 统计页面密码框上提示文本 stats realm Haproxy\ Statistics # 统计页面用户名和密码设置 stats auth admin:admin # 隐藏统计页面上HAProxy的版本信息 #stats hide-version listen login bind *:9999 mode tcp balance roundrobin option httpchk #maxconn 50000 #log 127.0.0.1 local0 debug 3、haproxy启动脚本 /etc/init.d/haproxy#! /bin/bash # chkconfig: - 85 15 # description: haproxy is a World Wide Web server. It is used to serve PROGDIR=/opt/haproxy PROGNAME=haproxy DAEMON=$PROGDIR/sbin/$PROGNAME CONFIG=$PROGDIR/conf/$PROGNAME.conf PIDFILE=$PROGDIR/run/$PROGNAME.pid DESC=&quot;HAProxy daemon&quot; SCRIPTNAME=/opt/haproxy/init.d/$PROGNAME # Gracefully exit if the package has been removed. test -x $DAEMON || exit 0 start() { echo -n &quot;Starting $DESC: $PROGNAME&quot; $DAEMON -f $CONFIG echo &quot;.&quot; } stop() { echo -n &quot;Stopping $DESC: $PROGNAME&quot; cat $PIDFILE | xargs kill echo &quot;.&quot; } reload() { echo -n &quot;reloading $DESC: $PROGNAME&quot; $DAEMON -f $CONFIG -p $PIDFILE -sf $(cat $PIDFILE) } case &quot;$1&quot; in start) start ;; stop) stop ;; reload) reload ;; *) echo &quot;Usage: $SCRIPTNAME {start|stop|reload}&quot; &gt;&amp;2 exit 1 ;; esac exit 0 4、启动haproxy,并加入到开启启动chmod +x /etc/init.d/haproxy chkconfig haproxy op service haproxy start 5、安装nginx 并支持数字证书yum -y install git patch gcc gcc-c++ readline-devel zlib-devel libffi-devel \ openssl openssl-devel make autoconf automake libtool bison libxml2 \ libxml2-devel libxslt-devel libyaml-devel python python-docutils \ cmake imake expat-devel libaio libaio-devel bzr ncurses-devel wget \ libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel \ pcre-devel curl-devel libmcrypt libmcrypt-devel 6、下载安装openssl cd /tmp wget https://www.openssl.org/source/openssl-1.1.0c.tar.gz tar -xvf openssl-1.1.0c.tar.gz cd /tmp/openssl-1.1.0c ./config --openssldir=/usr/local/ssl make &amp;&amp; make install ./config shared --openssldir=/usr/local/ssl make clean make &amp;&amp; make install 7、下载安装 nginxcd /tmp wget http://nginx.org/download/nginx-1.11.7.tar.gz groupadd -r nginx useradd -g nginx -r nginx -s /bin/false tar -xvf nginx-1.11.7.tar.gz cd /tmp/nginx-1.11.7 ./configure --prefix=/usr/local/nginx \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --pid-path=/var/run/nginx.pid \ --lock-path=/var/run/nginx.lock \ --http-client-body-temp-path=/var/cache/nginx/client_temp \ --http-proxy-temp-path=/var/cache/nginx/proxy_temp \ --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \ --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \ --http-scgi-temp-path=/var/cache/nginx/scgi_temp \ --user=nginx \ --group=nginx \ --with-http_ssl_module \ --with-http_realip_module \ --with-http_addition_module \ --with-http_sub_module \ --with-http_dav_module \ --with-http_flv_module \ --with-http_mp4_module \ --with-http_gunzip_module \ --with-http_gzip_static_module \ --with-http_random_index_module \ --with-http_secure_link_module \ --with-http_stub_status_module \ --with-http_auth_request_module \ --with-threads \ --with-stream \ --with-openssl=/tmp/openssl-1.1.0c \ --with-stream_ssl_module \ --with-http_slice_module \ --with-mail \ --with-mail_ssl_module \ --with-file-aio \ --with-http_v2_module \ --with-ipv6 mkdir -pv /var/cache/nginx/{client_temp,proxy_temp,fastcgi_temp,uwsgi_temp,scgi_temp} mkdir -p /etc/nginx/conf.d make &amp;&amp; make install 8、nginx配置文件修改/etc/nginx/nginx.confuser nginx;worker_processes 1; error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid; events { worker_connections 1024;} http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; keepalive_timeout 65; gzip on; include /etc/nginx/conf.d/*.conf; } 添加nginx默认web配置文件/etc/nginx/conf.d/default.confserver { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root /usr/local/nginx/html; index index.php index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \.php$ { root /usr/local/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } location ~* ^.+\.(jpg|jpeg|gif|png|bmp)$ { access_log off; root opencart; expires 30d; break; } } 9、创建nginx启动脚本 /etc/init.d/nginx# chkconfig: 2345 10 90 # description: Start and Stop redis PATH=/usr/local/bin:/sbin:/usr/bin:/bin EXEC=/usr/sbin/nginx PIDFILE=/var/run/nginx.pid CONF=&quot;/etc/nginx/nginx.conf&quot; AUTH=&quot;1234&quot; case &quot;$1&quot; in start) if [ -f $PIDFILE ] then echo &quot;$PIDFILE exists, process is already running or crashed.&quot; else echo &quot;Starting nginx server...&quot; $EXEC &amp; fi if [ &quot;$?&quot;=&quot;0&quot; ] then echo &quot;nginx is running...&quot; fi ;; stop) if [ ! -f $PIDFILE ] then echo &quot;$PIDFILE exists, process is not running.&quot; else PID=$(cat $PIDFILE) echo &quot;Stopping...&quot; kill -9 $PID PID=$(pidof nginx) kill -9 $PID rm -rf /var/run/nginx.pid sleep 2 while [ -x $PIDFILE ] do echo &quot;Waiting for nginx to shutdown...&quot; sleep 1 done echo &quot;nginx stopped&quot; fi ;; restart|reload) ${0} stop ${0} start ;; *) echo &quot;Usage: /etc/init.d/nginx {start|stop|restart|reload}&quot; &gt;&amp;2 exit 1 esac 10、设置nginx开机启动chmod +x /etc/init.d/nginx chkconfig nginx on service nginx start 六、安装consul-template 实现服务自动发现1、下载consul-templatecd /tmp wget https://releases.hashicorp.com/consul-template/0.16.0/consul-template_0.16.0_linux_amd64.zip yum -y install unzip unzip /tmp/consul-template_0.16.0_linux_amd64.zip -d /usr/bin/ 2、consul-template haproxy配置cat &gt; /opt/consul/conf/haproxy_ctmpl.json &lt;&lt; EOF consul = &quot;127.0.0.1:8500&quot; template { source = &quot;/opt/haproxy/conf/haproxy.ctmpl&quot; destination = &quot;/opt/haproxy/conf/haproxy.conf&quot; command = &quot;/etc/init.d/haproxy reload&quot; } EOF 3、haproxy.ctmpl配置 /opt/haproxy/conf/haproxy.ctmpl global log 127.0.0.1 local0 #log 127.0.0.1 local1 notice #log loghost local0 info maxconn 50000 chroot /opt/haproxy uid 99 gid 99 daemon nbproc 2 pidfile /opt/haproxy/run/haproxy.pid #debug #quiet defaults mode tcp option dontlognull option forwardfor option redispatch retries 2 balance static-rr stats enable stats uri /ha?stats timeout connect 3000 timeout client 50000 timeout server 50000 listen admin_stat bind *:8888 mode http #log global stats refresh 30s stats uri /admin?stats stats realm Haproxy\ Statistics stats auth admin:admin #stats hide-version frontend www bind *:80 mode http acl apache hdr(HOST) apache.zone.com acl nginx hdr(HOST) nginx.zone.com use_backend apache.qkazone.com if apache use_backend nginx.qkazone.com if nginx backend apache.zone.com balance roundrobin mode http {{range service "apache-php-80"}} server apache {{.Address}}:{{.Port}} check {{end}} backend nginx.zone.com mode http balance roundrobin {{range service "nginx-80"}} server nginx {{.Address}}:{{.Port}} check {{end}} listen login bind *:9999 mode tcp balance roundrobin #log 127.0.0.1 local0 debug {{range service "centos7"}} server ssh {{.Address}}:{{.Port}} check {{end}} 4、配置consul-template haproxy 启动脚本 /etc/init.d/haproxy_ctmpl#!/bin/bash # chkconfig: 2345 10 90 # description: Start and Stop redis PATH=/usr/local/bin:/sbin:/usr/bin:/bin EXEC=/usr/bin/consul-template CONF=&quot;/opt/consul/conf/haproxy_ctmpl.json&quot; case &quot;$1&quot; in start) PID=$(ps -ef | grep -v grep | grep &quot;$EXEC -config $CONF&quot; | awk &#39;{print $2}&#39;) if [ -n &quot;$PID&quot; ] then echo &quot;haproxy_ctmpl is running...&quot; else echo &quot;Starting haproxy_ctmpl server...&quot; $EXEC -config $CONF &gt; /tmp/haproxy_ctmpl.out 2&gt;&amp;1 &amp; fi ;; stop) PID=$(ps -ef | grep -v grep | grep &quot;$EXEC -config $CONF&quot; | awk &#39;{print $2}&#39;) if [ -n &quot;$PID&quot; ] then echo &quot;Stopping...&quot; kill -9 $PID sleep 2 else echo &quot;haproxy_ctmpl exists, process is not running.&quot; fi ;; restart|force-reload) ${0} stop ${0} start ;; *) echo &quot;Usage: /etc/init.d/tmpl {start|stop|restart|force-reload}&quot; &gt;&amp;2 exit 1 esac 5、设置开机启动，启动chmod +x /etc/init.d/haproxy_ctmpl chkconfig haproxy_ctmpl on service haproxy_ctmpl start 6、consul-template nginx配置 /opt/consul/conf/nginx_ctmpl.jsoncat &gt; /opt/consul/conf/nginx_ctmpl.json &lt;&lt; EOF consul = &quot;127.0.0.1:8500&quot; template { source = &quot;/etc/nginx/conf.d/nginx_web.ctmpl&quot; destination = &quot;/etc/nginx/conf.d/nginx_web.conf&quot; command = &quot;/usr/sbin/nginx -s reload&quot; } EOF 7、/etc/nginx/conf.d/nginx_web.ctmpl 配置upstream apache { ip_hash; # Refer: http://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream # least_conn; # least_time; {{range service "apache-php-80"}} server {{.Address}}:{{.Port}} fail_timeout=0; {{end}} keepalive 64; } server { listen 80; server_name apache.zone.com; location / { client_max_body_size 0; proxy_connect_timeout 300s; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 32k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_redirect off; proxy_hide_header Vary; proxy_set_header Accept-Encoding &#39;&#39;; proxy_set_header Host $host; proxy_set_header Referer $http_referer; proxy_set_header Cookie $http_cookie; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_headers_hash_max_size 51200; proxy_headers_hash_bucket_size 6400; proxy_pass http://apache/; } } upstream nginx { ip_hash; # Refer: http://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream # least_conn; # least_time; {{range service "nginx-80"}} server {{.Address}}:{{.Port}} fail_timeout=0; {{end}} keepalive 64; } server { listen 80; server_name nginx.zone.com; location / { client_max_body_size 0; proxy_connect_timeout 300s; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 32k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_redirect off; proxy_hide_header Vary; proxy_set_header Accept-Encoding &#39;&#39;; proxy_set_header Host $host; proxy_set_header Referer $http_referer; proxy_set_header Cookie $http_cookie; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_headers_hash_max_size 51200; proxy_headers_hash_bucket_size 6400; proxy_pass http://nginx/; } } 8、配置consul-template nginx启动脚本 /etc/init.d/nginx_ctmpl#!/bin/bash # chkconfig: 2345 10 90 # description: Start and Stop redis PATH=/usr/local/bin:/sbin:/usr/bin:/bin EXEC=/usr/bin/consul-template CONF=&quot;/opt/consul/conf/nginx_ctmpl.json&quot; case &quot;$1&quot; in start) PID=$(ps -ef | grep -v grep | grep &quot;$EXEC -config $CONF&quot; | awk &#39;{print $2}&#39;) if [ -n &quot;$PID&quot; ] then echo &quot;haproxy_ctmpl is running...&quot; else echo &quot;Starting haproxy_ctmpl server...&quot; $EXEC -config $CONF &gt; /tmp/nginx_ctmpl.out 2&gt;&amp;1 &amp; fi ;; stop) PID=$(ps -ef | grep -v grep | grep &quot;$EXEC -config $CONF&quot; | awk &#39;{print $2}&#39;) if [ -n &quot;$PID&quot; ] then echo &quot;Stopping...&quot; kill -9 $PID sleep 2 else echo &quot;haproxy_ctmpl exists, process is not running.&quot; fi ;; restart|force-reload) ${0} stop ${0} start ;; *) echo &quot;Usage: /etc/init.d/tmpl {start|stop|restart|force-reload}&quot; &gt;&amp;2 exit 1 esac 9、设置开机启动chmod +x /etc/init.d/nginx_ctmpl chkconfig nginx_ctmpl on service nginx_ctmpl start 七、测试是否自动发现docker run -ti -d -p :80 eboraas/apache-php docker run -d -ti -p :80 nginx 1、consul webhttp://192.168.1.66:8500/ui/#/dc1/services 2、shipyard webhttp://192.168.1.23:8080账号admin密码 shipyard 3、haproxy webhttp://192.168.1.14:8888/admin?stats账号：admin 密码admin`]]></content>
      <categories>
        <category>dockers</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux自动化运维</tag>
        <tag>swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-redis集群]]></title>
    <url>%2F2018%2F04%2F08%2Fdocker-redis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[前言Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。此文只要是针对基于docker部署redis集群，实现主从同步master 192.168.1.14slave 192.168.1.15 master操作1.创建数据文件mkdir /opt/redis 2.拉取redis镜像docker pull benyoo/redis:3.2.5 3.配置redis文件echo &#39;bind 0.0.0.0 protected-mode yes port 6379 tcp-backlog 511 timeout 0 tcp-keepalive 300 daemonize no supervised no pidfile /var/run/redis_6379.pid loglevel notice logfile &quot;&quot; databases 8 save 900 1 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes dbfilename dump.rdb dir /data/redis slave-serve-stale-data yes slave-read-only yes repl-diskless-sync no repl-diskless-sync-delay 5 repl-disable-tcp-nodelay no slave-priority 100 appendonly no appendfilename &quot;appendonly.aof&quot; appendfsync everysec no-appendfsync-on-rewrite no auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb aof-load-truncated yes lua-time-limit 5000 slowlog-log-slower-than 10000 slowlog-max-len 128 latency-monitor-threshold 0 notify-keyspace-events &quot;&quot; hash-max-ziplist-entries 512 hash-max-ziplist-value 64 list-max-ziplist-size -2 list-compress-depth 0 set-max-intset-entries 512 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 hll-sparse-max-bytes 3000 activerehashing yes client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 hz 10 aof-rewrite-incremental-fsync yes masterauth ZDU0NTlkNDY5NWZi requirepass ZDU0NTlkNDY5NWZi&#39; &gt;/opt/redis/redis.conf 4.配置防火墙iptables -I INPUT 5 -p tcp -m state --state NEW -m tcp -m comment --comment &quot;REDIS_SERVER&quot; -m multiport --dports 6379 -j ACCEPT iptables -nvxL --lin 5.启动redis容器docker run -d \ --privileged=true \ --name redis-master \ --restart=always \ -p 6379:6379 -v /opt/redis/redis.conf:/etc/redis.conf \ -v /etc/localtime:/etc/localtime \ benyoo/redis:3.2.5 slave上操作1.创建数据文件mkdir /opt/redis 2.拉取redis镜像 docker pull benyoo/redis:3.2.5 3.配置redis文件 echo &#39;bind 0.0.0.0 protected-mode yes port 6379 tcp-backlog 511 timeout 0 tcp-keepalive 300 daemonize no supervised no pidfile /var/run/redis_6379.pid loglevel notice logfile &quot;&quot; databases 8 save 900 1 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes dbfilename dump.rdb dir /data/redis slave-serve-stale-data yes slave-read-only yes repl-diskless-sync no repl-diskless-sync-delay 5 repl-disable-tcp-nodelay no slave-priority 100 appendonly no appendfilename &quot;appendonly.aof&quot; appendfsync everysec no-appendfsync-on-rewrite no auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb aof-load-truncated yes lua-time-limit 5000 slowlog-log-slower-than 10000 slowlog-max-len 128 latency-monitor-threshold 0 notify-keyspace-events &quot;&quot; hash-max-ziplist-entries 512 hash-max-ziplist-value 64 list-max-ziplist-size -2 list-compress-depth 0 set-max-intset-entries 512 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 hll-sparse-max-bytes 3000 activerehashing yes client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 hz 10 aof-rewrite-incremental-fsync yes slaveof 192.168.1.14 6379 masterauth ZDU0NTlkNDY5NWZi requirepass ZDU0NTlkNDY5NWZi&#39; &gt;/opt/redis/redis.conf 4.配置防火墙iptables -I INPUT 5 -p tcp -m state --state NEW -m tcp -m comment --comment &quot;REDIS_SERVER&quot; -m multiport --dports 6379 -j ACCEPT iptables -nvxL --lin 5.启动redis容器docker run -d \ --privileged=true \ --name redis-slave \ --restart=always \ -p 6379:6379 -v /opt/redis/redis.conf:/opt/redis/redis.conf \ -v /etc/localtime:/etc/localtime \ benyoo/redis:3.2.5 测试docker exec -it redis redis-cli -h 192.168.1.15 -a ZDU0NTlkNDY5NWZi info replication # Replication role:slave master_host:192.168.1.14 master_port:6379 master_link_status:up master_last_io_seconds_ago:9 master_sync_in_progress:0 slave_repl_offset:281 slave_priority:100 slave_read_only:1 connected_slaves:0 master_repl_offset:0 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 docker exec -it redis redis-cli -h 192.168.1.14 -a ZDU0NTlkNDY5NWZi info replication # Replication role:master connected_slaves:1 slave0:ip=192.168.1.15,port=6379,state=online,offset=295,lag=1 master_repl_offset:295 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:2 repl_backlog_histlen:294 docker exec -it redis redis-cli -h 192.168.1.14 -a ZDU0NTlkNDY5NWZi set Test_Write_key www.shangtv.cn #创建数据 OK docker exec -it redis redis-cli -h 192.168.1.14 -a ZDU0NTlkNDY5NWZi get Test_Write_key www.shangtv.cn]]></content>
      <categories>
        <category>dockers</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux自动化运维</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[registry v2搭建]]></title>
    <url>%2F2018%2F04%2F08%2Fregistry-v2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[前言新版 registry v2对镜像存储格式进行了重新设计，并且和旧版还不兼容。registry v2是由go语言开发，docker从1.6版本开始支持registry v2，之前python开发的老版registry在网上已被标为废弃了（没有维护更新，但也可以用）。 之前在测试环境搭建了一个老版的registry，用了也比较久了。为了跟上技术的脚步，也准备今后使用新版registry v2。由于对旧版是不兼容的，所以之前仓库的数据目录还不能直接拿来挂载，只好重新做个新的，镜像只好等以后慢慢再放上去了。下面对我这次配置的步骤简单的介绍一下。 服务器环境本次使用centos7.3的操作系统，服务器IP假设为：192.168.0.100预先装好docker服务，操作如下： 添加docker.repo安装源，写入文件tee /etc/yum.repos.d/docker.repo&lt;&lt;EOF [dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/7/ enabled=1 gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg EOF 安装dockeryum install docker-engine -y systemctl enable docker systemctl start docker 1. 获取最新的registry的容器,了解到目前最新版为2.4.1，于是直接使用docker pull命令从公用仓库去拉即可docker pull registry:2.4.1 2. 运行registry:2.4.1容器这里需要注意的是新registry仓库数据目录的位置。之前老版的位置是/tmp/registry，hub.docker.com上的演示命令里写的是/tmp/registry-dev，其实这个不对。试验证明，新registry的仓库目录是在/var/lib/registry，所以运行时挂载目录需要注意。 docker run -d -p 5000:5000 --restart=always \ -v /opt/registry-var/:/var/lib/registry/ \ registry:2.4.1 -v选项指定将/opt/registry-var/目录挂载给/var/lib/registry/当使用curl http://192.168.0.100:5000/v2/_catalog能看到json格式的返回值时，说明registry已经运行起来了。 3. 修改配置文件以指定registry地址上面registry虽然已经运行起来了，但是如果想用push命令上传镜像是会报错的，需要在配置文件中指定registry的地址。在/lib/systemd/system/docker.service文件中添加一下配置：–insecure-registry 192.168.0.100:5000’ 为了配置简单，省去安全相关的配置，这里使用–insecure-registry选项修改配置文件后，一定要重启docker服务才能生效， systemctl restart docker 这时再push就可以上传镜像到所搭建的registry仓库了。需要注意的是，上传前要先给镜像tag一个192.168.0.100:5000/为前缀的名字，这样才能在push的时候存到私库。 docker tag docker.io/registry:2.4.1 192.168.0.100:5000/registry:2.4.1 docker push 192.168.0.100:5000/registry:2.4.1 4. 配置带用户权限的registry到上面为止，registry已经可以使用了。如果想要控制registry的使用权限，使其只有在登录用户名和密码之后才能使用的话，还需要做额外的设置。 registry的用户名密码文件可以通过htpasswd来生成： mkdir /opt/registry-var/auth/ docker run --entrypoint htpasswd registry:2.4.1 -Bbn felix felix &gt;&gt; /opt/registry-var/auth/htpasswd 上面这条命令是为felix用户名生成密码为felix的一条用户信息，存在/opt/registry-var/auth/htpasswd文件里面，文件中存的密码是被加密过的。使用带用户权限的registry时候，容器的启动命令就跟上面不一样了，将之前的容器停掉并删除，然后执行下面的命令： docker run -d -p 5000:5000 --restart=always \ -v /opt/registry-var/auth/:/auth/ \ -e &quot;REGISTRY_AUTH=htpasswd&quot; \ -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; \ -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \ -v /opt/registry-var/:/var/lib/registry/ \ registry:2.4.1 这时，如果直接想查看仓库信息、pull或push都会出现权限报错。必须先使用docker login 命令来登录私有仓库： docker login 192.168.0.100:5000 根据提示，输入用户名和密码即可。如果登录成功，会在/root/.docker/config.json文件中保存账户信息，这样就可以继续使用了。]]></content>
      <tags>
        <tag>docker</tag>
        <tag>linux自动化运维</tag>
        <tag>docker-registry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd集群]]></title>
    <url>%2F2018%2F04%2F08%2Fetcd%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[前言Etcd:一个键值存储仓库，主要用于配置共享和服务发现。优点： 简单：支持 curl 方式的用户 API (HTTP+JSON) 安全：可选 SSL 客户端证书认证 快速：单实例可达每秒 1000 次写操作 可靠：使用 Raft 实现分布式 本文主要阐述集群etcd的部署安装etcd可以通过源码编译安装，也可以用yum安装，这里实验用yum安装Configure epel yum wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm &amp;&amp; rpm -ivh epel-release-latest-7.noarch.rpm install etcd yum install -y etcd configure host echo &quot;etcd1 192.168.1.100&quot; &gt;&gt; /etc/hosts echo &quot;etcd2 192.168.1.200&quot; &gt;&gt; /etc/hosts IP=$(ifconfig eth1 |awk -F &#39;[: ]+&#39; &#39;NR==2{print $3}&#39;) IP1=192.168.1.100 IP2=192.168.1.200 HOST=&quot;etcd1=http://192.168.1.100:2380,etcd2=http://192.168.1.200:2380&quot; function node1{ #Configure the node1 etcd file sed -i &#39;s#\#ETCD_LISTEN_PEER_URLS=&quot;http://localhost:2380&quot;#ETCD_LISTEN_PEER_URLS=&quot;http://${IP1}:2380&quot;#g&#39; /etc/etcd/etcd.conf sed -i &#39;s#ETCD_LISTEN_CLIENT_URLS=&quot;http://localhost:2379&quot;#ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;#g&#39; /etc/etcd/etcd.conf sed -i &#39;s#ETCD_ADVERTISE_CLIENT_URLS=&quot;http://localhost:2379&quot;#ETCD_ADVERTISE_CLIENT_URLS=&quot;http://${IP1}:2379&quot;#g&#39; /etc/etcd/etc.conf sed -i &#39;s#\#ETCD_INITIAL_CLUSTER=&quot;default=http://localhost:2380&quot;#ETCD_INITIAL_CLUSTER=&quot;${HOST}&quot;#&#39;g } function node2{ #Configure the node2 etcd file sed -i &#39;s#\#ETCD_LISTEN_PEER_URLS=&quot;http://localhost:2380&quot;#ETCD_LISTEN_PEER_URLS=&quot;http://${IP2}:2380&quot;#g&#39; /etc/etcd/etcd.conf sed -i &#39;s#ETCD_LISTEN_CLIENT_URLS=&quot;http://localhost:2379&quot;#ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;#g&#39; /etc/etcd/etcd.conf sed -i &#39;s#ETCD_ADVERTISE_CLIENT_URLS=&quot;http://localhost:2379&quot;#ETCD_ADVERTISE_CLIENT_URLS=&quot;http://${IP2}:2379&quot;#g&#39; /etc/etcd/etc.conf sed -i &#39;s#\#ETCD_INITIAL_CLUSTER=&quot;default=http://localhost:2380&quot;#ETCD_INITIAL_CLUSTER=&quot;${HOST}&quot;#g&#39; /etc/etcd/etc.conf } function start{ systemctl enable etcd systemctl restart etcd systemctl status etcd } if [ &quot;$IP&quot;==&quot;$IP1&quot; ];then node1 start else node2 start fi look etcd node list etcdctl member list look etcd node status etcdctl cluster-health]]></content>
      <tags>
        <tag>docker</tag>
        <tag>linux自动化运维</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Add User Script]]></title>
    <url>%2F2018%2F04%2F04%2FAdd-User-Script%2F</url>
    <content type="text"><![CDATA[前言可用于服务器自动添加用户，并发送邮件实现shell自动化建设 #!/bin/bash password=&quot;password&quot; ip=`ifconfig eth1 |grep inet |awk &#39;{printf &quot;IP:&quot;}&#39;&#39;{print $2}&#39;` echo &quot;请输入要创建的用户名：&quot; read username echo &quot;您输入的用户名为: $username&quot; egrep &quot;^servergroups&quot; /etc/group &gt;&amp; /dev/null if [ $? -ne 0 ] then groupadd servergroups else echo &quot;已存在servergroups组&quot; fi egrep &quot;^$username&quot; /etc/passwd &gt;&amp; /dev/null if [ $? -ne 0 ] then useradd $username &amp;&amp; \ usermod -aG servergroups $username &amp;&amp; \ echo $username | passwd --stdin $username chage -d 0 $username echo &quot;创建 $username 用户成功&quot; #echo &quot;密码为:$password&quot; id $username text=&quot;用户名：$username\n密码为：$username\n$ip\n注意：第一次登陆必须要修改密码!!!!&quot; echo -e &quot;$text&quot; | mail -s &quot;$username,服务器用户创建成功，请及时修改密码!!&quot; $username@qq.com else echo &quot;$username 已存在&quot; id $username fi]]></content>
      <tags>
        <tag>linux自动化运维</tag>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好，Oliver]]></title>
    <url>%2F2018%2F04%2F04%2F%E4%BD%A0%E5%A5%BD%EF%BC%8COliver%2F</url>
    <content type="text"></content>
  </entry>
</search>
